{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "This notebook preprocesses the following raw data for the period Dec 2019 to Feb 2020 and Dec 2021 to Feb 2022:\n",
    "- NYC Yellow Taxi Data \n",
    "- NYC For Hire Vehicles (FHV) Data\n",
    "- NYC COVID-19 Data (Dec 2021-Feb 2022 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/09 14:15:25 WARN Utils: Your hostname, kelman_HP_ENVY resolves to a loopback address: 127.0.1.1; using 172.26.243.108 instead (on interface eth0)\n",
      "22/08/09 14:15:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/09 14:15:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "output_relative_dir = '../data/raw/'\n",
    "\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "\n",
    "if not os.path.exists(output_relative_dir + 'NYC TLC Data'):\n",
    "    os.makedirs(output_relative_dir + 'NYC TLC Data')\n",
    "\n",
    "if not os.path.exists(output_relative_dir + \"External Data\"):\n",
    "    os.makedirs(output_relative_dir + \"External Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed downloading yellow_tripdata_2019-12.parquet\n",
      "Completed downloading yellow_tripdata_2020-01.parquet\n",
      "Completed downloading yellow_tripdata_2020-02.parquet\n",
      "Completed downloading yellow_tripdata_2021-12.parquet\n",
      "Completed downloading yellow_tripdata_2022-01.parquet\n",
      "Completed downloading yellow_tripdata_2022-02.parquet\n",
      "Completed downloading fhvhv_tripdata_2019-12.parquet\n",
      "Completed downloading fhvhv_tripdata_2020-01.parquet\n",
      "Completed downloading fhvhv_tripdata_2020-02.parquet\n",
      "Completed downloading fhvhv_tripdata_2021-12.parquet\n",
      "Completed downloading fhvhv_tripdata_2022-01.parquet\n",
      "Completed downloading fhvhv_tripdata_2022-02.parquet\n"
     ]
    }
   ],
   "source": [
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"\n",
    "\n",
    "def tlc_data_download(name, year, month):\n",
    "    \n",
    "    month = str(month).zfill(2)\n",
    "\n",
    "    output_dir = f\"{name}_tripdata_{year}-{month}.parquet\"\n",
    "    url =f'{URL_TEMPLATE}{output_dir}'\n",
    "\n",
    "    urlretrieve(url, f\"{output_relative_dir}NYC TLC Data/{output_dir}\")\n",
    "    print(f\"Completed downloading {output_dir}\")\n",
    "\n",
    "for name in ('yellow', 'fhvhv'):\n",
    "    tlc_data_download(name, 2019, 12)\n",
    "    tlc_data_download(name, 2020, 1)\n",
    "    tlc_data_download(name, 2020, 2)\n",
    "    tlc_data_download(name, 2021, 12)\n",
    "    tlc_data_download(name, 2022, 1)\n",
    "    tlc_data_download(name, 2022, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed downloading COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv\n"
     ]
    }
   ],
   "source": [
    "covid_url = 'https://data.cityofnewyork.us/api/views/rc75-m7u3/rows.csv?accessType=DOWNLOAD'\n",
    "covid_output_dir = 'COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv'\n",
    "urlretrieve(covid_url, f\"{output_relative_dir}External Data/{covid_output_dir}\")\n",
    "print(f\"Completed downloading {covid_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Preprocess TLC Data</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load yellow taxi data\n",
    "yellow_2019_12_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2019-12.parquet', header=True)\n",
    "yellow_2020_01_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2020-01.parquet', header=True)\n",
    "yellow_2020_02_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2020-02.parquet', header=True)\n",
    "\n",
    "yellow_2021_12_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2021-12.parquet', header=True)\n",
    "yellow_2022_01_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2022-01.parquet', header=True)\n",
    "yellow_2022_02_sdf = spark.read.parquet('../data/raw/NYC TLC Data/yellow_tripdata_2022-02.parquet', header=True)\n",
    "\n",
    "# load FHV data\n",
    "fhvhv_2019_12_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2019-12.parquet', header=True)\n",
    "fhvhv_2020_01_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2020-01.parquet', header=True)\n",
    "fhvhv_2020_02_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2020-02.parquet', header=True)\n",
    "\n",
    "fhvhv_2021_12_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2021-12.parquet', header=True)\n",
    "fhvhv_2022_01_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2022-01.parquet', header=True)\n",
    "fhvhv_2022_02_sdf = spark.read.parquet('../data/raw/NYC TLC Data/fhvhv_tripdata_2022-02.parquet', header=True)\n",
    "\n",
    "# merge datasets categorised by type and period\n",
    "yellow_19_20_sdf = yellow_2019_12_sdf.unionAll(yellow_2020_01_sdf).unionAll(yellow_2020_02_sdf)\n",
    "yellow_21_22_sdf = yellow_2021_12_sdf.unionAll(yellow_2022_01_sdf).unionAll(yellow_2022_02_sdf)\n",
    "\n",
    "fhvhv_19_20_sdf = fhvhv_2019_12_sdf.unionAll(fhvhv_2020_01_sdf).unionAll(fhvhv_2020_02_sdf)\n",
    "fhvhv_21_22_sdf = fhvhv_2021_12_sdf.unionAll(fhvhv_2022_01_sdf).unionAll(fhvhv_2022_02_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature engineering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yellow Taxis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_taxi_feature_eng(data_sdf):\n",
    "    # trip duration in minutes\n",
    "    data_sdf_eng = data_sdf.withColumn(\n",
    "        'trip_time',\n",
    "        (F.col('tpep_dropoff_datetime').cast('long') - F.col('tpep_pickup_datetime').cast('long'))/60\n",
    "    )\n",
    "\n",
    "    # pickup day is weekend or not\n",
    "    data_sdf_eng = data_sdf_eng.withColumn(\n",
    "        'is_weekend',\n",
    "        F.dayofweek(F.col('tpep_pickup_datetime')).isin([1, 7])\n",
    "    )\n",
    "\n",
    "    # tip percentage over total amount paid\n",
    "    data_sdf_eng = data_sdf_eng.withColumn(\n",
    "        'tip_percent',\n",
    "        (F.col('tip_amount') / F.col('total_amount')) * 100\n",
    "    )\n",
    "\n",
    "    return data_sdf_eng\n",
    "\n",
    "yellow_19_20_sdf_eng = yellow_taxi_feature_eng(yellow_19_20_sdf)\n",
    "yellow_21_22_sdf_eng = yellow_taxi_feature_eng(yellow_21_22_sdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FHV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhvhv_feature_eng(data_sdf):\n",
    "    # trip duration in mniutes\n",
    "    data_sdf_eng = data_sdf.withColumn(\n",
    "        'trip_time',\n",
    "        F.col('trip_time')/60\n",
    "    )\n",
    "\n",
    "    # fill null values in airport_fee with 0\n",
    "    data_sdf_eng = data_sdf_eng.na.fill(value=0, subset=['airport_fee'])\n",
    "\n",
    "    # total amount paid by passenger\n",
    "    data_sdf_eng = data_sdf_eng.withColumn(\n",
    "        'total_amount',\n",
    "        F.col('base_passenger_fare') + F.col('tolls') + F.col('sales_tax') + F.col('tips') + F.col('airport_fee')\n",
    "    )\n",
    "\n",
    "    # pickup day is weekend or not\n",
    "    data_sdf_eng = data_sdf_eng.withColumn(\n",
    "        'is_weekend',\n",
    "        F.dayofweek(F.col('pickup_datetime')).isin([1, 7])\n",
    "    )\n",
    "\n",
    "    # tip percentage over total amount paid\n",
    "    data_sdf_eng = data_sdf_eng.withColumn(\n",
    "        'tip_percent',\n",
    "        (F.col('tips') / F.col('total_amount')) * 100\n",
    "    )\n",
    "\n",
    "    return data_sdf_eng\n",
    "\n",
    "fhvhv_19_20_sdf_eng = fhvhv_feature_eng(fhvhv_19_20_sdf)\n",
    "fhvhv_21_22_sdf_eng = fhvhv_feature_eng(fhvhv_21_22_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Outlier Detection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_time_clean_mask = (F.col('trip_time') > 0) & (F.col('trip_time') < 300)\n",
    "location_id_clean_mask = (((F.col('PULocationID') >= 1) & (F.col('PULocationID') <= 263))\n",
    "                            | ((F.col('DOLocationID') >= 1) & (F.col('DOLocationID') <= 263)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yellow Taxis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes for Yellow Taxis 2019-2020\n",
      "Original data size:  19600692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip time cleaned size:  19543652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=================================================>      (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location ID cleaned size:  19506018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Data sizes for Yellow Taxis 2019-2020\")\n",
    "print(\"Original data size: \", yellow_19_20_sdf_eng.count())\n",
    "print(\"Trip time cleaned size: \", yellow_19_20_sdf_eng.where(trip_time_clean_mask).count())\n",
    "print(\"Location ID cleaned size: \", yellow_19_20_sdf_eng.where(location_id_clean_mask).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes for Yellow Taxis 2021-2022\n",
      "Original data size:  8657731\n",
      "Trip time cleaned size:  8638019\n",
      "Location ID cleaned size:  8615868\n"
     ]
    }
   ],
   "source": [
    "print(\"Data sizes for Yellow Taxis 2021-2022\")\n",
    "print(\"Original data size: \", yellow_21_22_sdf_eng.count())\n",
    "print(\"Trip time cleaned size: \", yellow_21_22_sdf_eng.where(trip_time_clean_mask).count())\n",
    "print(\"Location ID cleaned size: \", yellow_21_22_sdf_eng.where(location_id_clean_mask).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data size for Yellow Taxi 2019-2020: 19450894\n",
      "Cleaned data size for Yellow Taxi 2021-2022: 8596662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow_19_20_sdf_cleaned = yellow_19_20_sdf_eng.where(trip_time_clean_mask)\n",
    "yellow_19_20_sdf_cleaned = yellow_19_20_sdf_cleaned.where(location_id_clean_mask)\n",
    "\n",
    "yellow_21_22_sdf_cleaned = yellow_21_22_sdf_eng.where(trip_time_clean_mask)\n",
    "yellow_21_22_sdf_cleaned = yellow_21_22_sdf_cleaned.where(location_id_clean_mask)\n",
    "                                                            \n",
    "print(\"Cleaned data size for Yellow Taxi 2019-2020:\", yellow_19_20_sdf_cleaned.count())   \n",
    "print(\"Cleaned data size for Yellow Taxi 2021-2022:\", yellow_21_22_sdf_cleaned.count())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FHV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes for FHVHV Trips 2019-2020\n",
      "Original data size:  64538369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip time cleaned size:  64536919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:=================================================>      (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location ID cleaned size:  64536983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Data sizes for FHVHV Trips 2019-2020\")\n",
    "print(\"Original data size: \", fhvhv_19_20_sdf_eng.count())\n",
    "print(\"Trip time cleaned size: \", fhvhv_19_20_sdf_eng.where(trip_time_clean_mask).count())\n",
    "print(\"Location ID cleaned size: \", fhvhv_19_20_sdf_eng.where(location_id_clean_mask).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes for FHVHV Trips 2021-2022\n",
      "Original data size:  46825369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip time cleaned size:  46824989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 343:================================================>      (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location ID cleaned size:  46824554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Data sizes for FHVHV Trips 2021-2022\")\n",
    "print(\"Original data size: \", fhvhv_21_22_sdf_eng.count())\n",
    "print(\"Trip time cleaned size: \", fhvhv_21_22_sdf_eng.where(trip_time_clean_mask).count())\n",
    "print(\"Location ID cleaned size: \", fhvhv_21_22_sdf_eng.where(location_id_clean_mask).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data size for FHVHV Trips 2019-2020: 19450894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=================================================>      (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data size for FHVHV Trips 2021-2022: 46824174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv_19_20_sdf_cleaned = fhvhv_19_20_sdf_eng.where(trip_time_clean_mask)\n",
    "fhvhv_19_20_sdf_cleaned = fhvhv_19_20_sdf_cleaned.where(location_id_clean_mask)\n",
    "\n",
    "fhvhv_21_22_sdf_cleaned = fhvhv_21_22_sdf_eng.where(trip_time_clean_mask)\n",
    "fhvhv_21_22_sdf_cleaned = fhvhv_21_22_sdf_cleaned.where(location_id_clean_mask)\n",
    "                                                            \n",
    "print(\"Cleaned data size for FHVHV Trips 2019-2020:\", yellow_19_20_sdf_cleaned.count())   \n",
    "print(\"Cleaned data size for FHVHV Trips 2021-2022:\", fhvhv_21_22_sdf_cleaned.count())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46824174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features_taxi = ['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID', \n",
    "                'store_and_fwd_flag', 'payment_type', 'fare_amount', 'extra',\n",
    "                'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "                'congestion_surcharge', 'airport_fee', 'trip_time']\n",
    "\n",
    "yellow_19_20_sdf_final = yellow_19_20_sdf_cleaned.drop(*drop_features_taxi)\n",
    "yellow_21_22_sdf_final = fhvhv_21_22_sdf_cleaned.drop(*drop_features_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow_19_20_sdf_final.write.mode('overwrite').parquet('../data/curated/yellow_19-20_curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow_21_22_sdf_final.write.mode('overwrite').parquet('../data/curated/yellow_21-22_curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46824174"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features_fhvhv = ['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
    "                        'request_datetime', 'on_scene_datetime', 'trip_miles', 'trip_time',\n",
    "                        'base_passenger_fare', 'tolls', 'bcf', 'sales_tax', 'congestion_surcharge',\n",
    "                        'airport_fee', 'tips', 'driver_pay', 'shared_request_flag', 'shared_match_flag',\n",
    "                        'access_a_ride_flag', 'wav_request_flag', 'wav_match_flag']\n",
    "\n",
    "fhvhv_19_20_sdf_final = fhvhv_19_20_sdf_cleaned.drop(*drop_features_fhvhv)\n",
    "fhvhv_21_22_sdf_final = fhvhv_21_22_sdf_cleaned.drop(*drop_features_fhvhv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv_19_20_sdf_final.write.mode('overwrite').parquet('../data/curated/fhvhv_19-20_curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv_21_22_sdf_final.write.mode('overwrite').parquet('../data/curated/fhvhv_21-22_curated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><u>Preprocess COVID Data</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load COVID-19 Daily Counts data\n",
    "covid_df = pd.read_csv('../data/raw/External Data/COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv')\n",
    "\n",
    "# select necessary features\n",
    "covid_df_selected = covid_df[['date_of_interest', 'CASE_COUNT', 'HOSPITALIZED_COUNT', 'DEATH_COUNT']]\n",
    "\n",
    "# select required data between dates 2021-12-01 and 2022-02-28\n",
    "covid_df_selected['date_of_interest'] = pd.to_datetime(covid_df_selected['date_of_interest'], format='%m/%d/%Y')\n",
    "mask = (covid_df_selected['date_of_interest'] >= '2021-12-01') & (covid_df_selected['date_of_interest'] <= '2022-2-28')\n",
    "covid_df_selected = covid_df_selected.loc[mask]\n",
    "\n",
    "covid_df_selected.to_parquet('../data/curated/nyc_covid_2021-2022_clean.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
